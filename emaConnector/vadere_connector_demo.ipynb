{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vadere EMA connector demo\n",
    "For more information on the use of the EMA Workbench, please refer to the [official EMA Workbench documentation](https://emaworkbench.readthedocs.io/en/latest/). This demo is based on the code provided on the documentation pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: imports\n",
    "The first step is to import the needed modules. This depends on the use and the type of analysis that is intended. The most important one here is the VadereModel from the model connectors. As said, please refer for more information on this to the [official EMA Workbench documentation](https://emaworkbench.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (perform_experiments, RealParameter, ema_logging,\n",
    "                           CategoricalParameter, MultiprocessingEvaluator,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)\n",
    "from ema_workbench.em_framework.parameters import Category\n",
    "from ema_workbench.connectors.vadere import VadereModel\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting up the model\n",
    "In this example, we use the Vadere model from this research.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model saves scalar results to a density.txt and speed.txt file.\n",
    "model = VadereModel('model', \n",
    "                    vadere_jar='vadere-console.jar',\n",
    "                    processor_files=[\n",
    "                        'density.txt',\n",
    "                        'speed.txt'\n",
    "                    ],\n",
    "                    model_file='baseCaseData.scenario',\n",
    "                    wd='/home/tevito/Documents/EPA/Year2/thesis/thesis-drive/model/connector/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of replications to handle model stochasticity\n",
    "model.replications = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for specifying model uncertainties (and potential levers), the Vadere model class can change any variable present in the model file (Vadere scenario). To realise this, a exact location to the variable of interest in the Vadere scenario file has to be specified. Vadere scenario files follow a nested dictionary structure. Therefore, the exact location of the variable should be passed in a list of argumentes, passed as one string. See the example below, that variates the spawnNumber and maxSpawnNumber of source 0 and source 1 in the Vadere model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](parameters.png \"Parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce complexity, this example demonstrates the specification of three parameter uncertainties (instead of the 10 illustrated above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.uncertainties = [\n",
    "    IntegerParameter(\n",
    "        name='spawnFrequencyA',\n",
    "        lower_bound=1,\n",
    "        upper_bound=5,\n",
    "        variable_name=[\n",
    "            '(\"scenario\", \"topography\", \"sources\", 0, \"distributionParameters\", \"updateFrequency\")',\n",
    "        ]\n",
    "    ),\n",
    "    RealParameter(\n",
    "        name='Î¼FreeFlowSpeed',\n",
    "        lower_bound=0.66,\n",
    "        upper_bound=1.16,\n",
    "        variable_name=[\n",
    "            '(\"scenario\", \"topography\", \"attributesPedestrian\", \"speedDistributionMean\")',\n",
    "        ]\n",
    "    ),\n",
    "    RealParameter(\n",
    "        name='pedPotentialHeight',\n",
    "        lower_bound=5.0,\n",
    "        upper_bound=50.0,\n",
    "        variable_name=[\n",
    "            '(\"scenario\", \"attributesModel\", \"org.vadere.state.attributes.models.AttributesPotentialCompactSoftshell\", \"pedPotentialHeight\")',\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model outcomes can be specified by passing the exact name as present in the output file (speed.txt here). The naming convention depends on the used Vadere data processors, but usually follows the name + id of the processor. When in doubt, it is advised to do a demo Vadere run using the Vadere software and to inspect the generated output files. Note that we take the mean of the outcomes here, since we specified multiple replications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.outcomes = [\n",
    "    ScalarOutcome(\n",
    "        name='meanSpeed',\n",
    "        variable_name='mean_area_speed_processor-PID6',\n",
    "        function=np.mean\n",
    "    ),\n",
    "    ScalarOutcome(\n",
    "        name='meanDensity',\n",
    "        variable_name='mean_density_counting_normed_processor-PID2',\n",
    "        function=np.mean\n",
    "    ),\n",
    "    ScalarOutcome(\n",
    "        name='maxDensity',\n",
    "        variable_name='max_density_counting_normed_processor-PID7',\n",
    "        function=np.mean\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Performing experiments\n",
    "The last step is to perform experiment with the Vadere model. Both sequential runs as runs in parallel are supported. Note however that a Vadere run can use a lot of RAM, and using all available CPU cores can lead to performance issues in some cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enable EMA logging\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in sequential 2 experiments\n",
    "results_sequential = perform_experiments(\n",
    "    model,\n",
    "    scenarios=2,\n",
    "    uncertainty_sampling='lhs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 8 scenarios * 1 policies * 1 model(s) = 8 experiments\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] 2 cases completed\n",
      "[MainProcess/INFO] 3 cases completed\n",
      "[MainProcess/INFO] 4 cases completed\n",
      "[MainProcess/INFO] 5 cases completed\n",
      "[MainProcess/INFO] 6 cases completed\n",
      "[MainProcess/INFO] 7 cases completed\n",
      "[MainProcess/INFO] 8 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[ForkPoolWorker-9/INFO] finalizing\n",
      "[ForkPoolWorker-11/INFO] finalizing\n",
      "[ForkPoolWorker-13/INFO] finalizing\n",
      "[ForkPoolWorker-10/INFO] finalizing\n",
      "[ForkPoolWorker-12/INFO] finalizing\n",
      "[ForkPoolWorker-14/INFO] finalizing\n",
      "[ForkPoolWorker-16/INFO] finalizing\n",
      "[ForkPoolWorker-15/INFO] finalizing\n"
     ]
    }
   ],
   "source": [
    "# run 8 experiments in parallel\n",
    "with MultiprocessingEvaluator(model, n_processes=8) as evaluator:\n",
    "        experiments, outcomes = evaluator.perform_experiments(\n",
    "                scenarios=8,\n",
    "                uncertainty_sampling='lhs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the results\n",
    "we can now look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(outcomes).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOBOL global sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.analyze import sobol\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    sa_results = evaluator.perform_experiments(\n",
    "        scenarios = 5000, \n",
    "        uncertainty_sampling='sobol'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = sa_results\n",
    "\n",
    "problem = get_SALib_problem(model.uncertainties)\n",
    "Si = sobol.analyze(problem, outcomes['max_P'],\n",
    "                   calc_second_order=True, print_to_console=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_filtered = {k:Si[k] for k in ['ST','ST_conf','S1','S1_conf']}\n",
    "Si_df = pd.DataFrame(scores_filtered, index=problem['names'])\n",
    "\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "indices = Si_df[['S1','ST']]\n",
    "err = Si_df[['S1_conf','ST_conf']]\n",
    "\n",
    "indices.plot.bar(yerr=err.values.T,ax=ax)\n",
    "fig.set_size_inches(8,6)\n",
    "fig.subplots_adjust(bottom=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0459880e260e094fc619a34e1d6d301a09b9955f38537d5834804b8e9b557f55"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('CrowdSim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
